{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4abaeee-0ec0-4199-b488-8eac41e659b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44343ae3-4467-43ad-9449-a148100f0f8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import textract\n",
    "from PyPDF2 import PdfReader\n",
    "import psycopg2\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import VertexAIEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.llms import VertexAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.vectorstores import Chroma\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "395da304-d62e-4796-92fe-bc0a751f2572",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def files(path):\n",
    "    \"\"\"\n",
    "    Function that returns only filenames (and not folder names)\n",
    "    \"\"\"\n",
    "    for file in os.listdir(path):\n",
    "        if os.path.isfile(os.path.join(path, file)):\n",
    "            yield file\n",
    "\n",
    "def create_data_packet(file_name, file_type, page_number, file_content):\n",
    "    \"\"\"Creating a simple dictionary to store all information (content and metadata)\n",
    "    extracted from the document\"\"\"\n",
    "    data_packet = {}\n",
    "    data_packet[\"file_name\"] = file_name\n",
    "    data_packet[\"file_type\"] = file_type\n",
    "    data_packet[\"page_number\"] = page_number\n",
    "    data_packet[\"content\"] = file_content\n",
    "    return data_packet\n",
    "\n",
    "def data_load():\n",
    "    \n",
    "    final_data = []\n",
    "    \n",
    "    for file_name in files(\"data/\"):\n",
    "        path = f\"data/{file_name}\"\n",
    "        _, file_type = os.path.splitext(path)\n",
    "        if file_type == \".pdf\":\n",
    "            # loading pdf files, with page numbers as metadata.\n",
    "            reader = PdfReader(path)\n",
    "            for i, page in enumerate(reader.pages):\n",
    "                text = page.extract_text()\n",
    "                if text:\n",
    "                    packet = create_data_packet(\n",
    "                        file_name, file_type, page_number=int(i + 1), file_content=text\n",
    "                    )\n",
    "\n",
    "                    final_data.append(packet)\n",
    "        else:\n",
    "            # loading other file types\n",
    "            text = textract.process(path).decode(\"utf-8\")\n",
    "            packet = create_data_packet(\n",
    "                file_name, file_type, page_number=None, file_content=text\n",
    "            )\n",
    "            final_data.append(packet)\n",
    "    return final_data\n",
    "\n",
    "data = data_load()\n",
    "\n",
    "def get_embedding_df(data):\n",
    "\n",
    "    df = pd.DataFrame(data[5:])\n",
    "\n",
    "    contents = []\n",
    "    for index, row in df.iterrows():\n",
    "        content = row.content\n",
    "        content = content.replace(\"취업규칙  \\n\",\"\")\n",
    "        content = re.sub(\"\\n[0-9]* \\n\",\"\", content)\n",
    "        contents.append(content.strip())\n",
    "    contents = ' '.join(contents)\n",
    "\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=[\"\\n\"],\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=100,\n",
    "        length_function=len,\n",
    "    )\n",
    "    chunked = []\n",
    "    splits = text_splitter.create_documents([contents])\n",
    "    index = 1\n",
    "    for s in splits:\n",
    "        r = {\"cid\": index, \"content\": s.page_content}\n",
    "        chunked.append(r)\n",
    "        index = index+1\n",
    "\n",
    "    embeddings_service = VertexAIEmbeddings(model_name=\"textembedding-gecko-multilingual@latest\")\n",
    "\n",
    "    def retry_with_backoff(func, *args, retry_delay=5, backoff_factor=2, **kwargs):\n",
    "        max_attempts = 10\n",
    "        retries = 0\n",
    "        for i in range(max_attempts):\n",
    "            try:\n",
    "                return func(*args, **kwargs)\n",
    "            except Exception as e:\n",
    "                print(f\"error: {e}\")\n",
    "                retries += 1\n",
    "                wait = retry_delay * (backoff_factor**retries)\n",
    "                print(f\"Retry after waiting for {wait} seconds...\")\n",
    "                time.sleep(wait)\n",
    "\n",
    "\n",
    "    batch_size = 5\n",
    "    for i in range(0, len(chunked), batch_size):\n",
    "        request = [x[\"content\"] for x in chunked[i : i + batch_size]]\n",
    "        response = retry_with_backoff(embeddings_service.embed_documents, request)\n",
    "        # Store the retrieved vector embeddings for each chunk back.\n",
    "        for x, e in zip(chunked[i : i + batch_size], response):\n",
    "            x[\"embedding\"] = e\n",
    "\n",
    "    # Store the generated embeddings in a pandas dataframe.\n",
    "    product_embeddings = pd.DataFrame(chunked)\n",
    "    return product_embeddings\n",
    "\n",
    "embedding_df = get_embedding_df(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d835cf1e-5703-43af-9913-04b4c5b4463b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DB 연결 함수\n",
    "def get_connection():\n",
    "    return psycopg2.connect(host=\"192.168.0.127\", dbname=\"vector_db\", user=\"postgres\", password=\"qwer1234\", port=5432)\n",
    "    #return psycopg2.connect(host=\"172.17.2.45\", dbname=\"vector_db\", user=\"postgres\", password=\"qwer1234\", port=5432)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2988d6ab-1ccc-402c-b3dd-ea014b4a5f2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL 15.4 (Debian 15.4-1.pgdg120+1) on aarch64-unknown-linux-gnu, compiled by gcc (Debian 12.2.0-14) 12.2.0, 64-bit\n"
     ]
    }
   ],
   "source": [
    "# DB 연결 테스트\n",
    "with get_connection() as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"select version()\")\n",
    "        result_one = cur.fetchone()\n",
    "        print(result_one[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae4bc860-583f-4805-acc6-dd160dbda55d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 테이블 초기화\n",
    "def create_table():\n",
    "    with get_connection() as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"\"\"\n",
    "                CREATE EXTENSION IF NOT EXISTS vector            \n",
    "            \"\"\")\n",
    "            cur.execute(\"\"\"\n",
    "                DROP TABLE IF EXISTS vntg_embeddings CASCADE            \n",
    "            \"\"\")\n",
    "            cur.execute(\"\"\"\n",
    "                CREATE TABLE vntg_embeddings (\n",
    "                    uuid SERIAL,\n",
    "                    content TEXT,\n",
    "                    embedding vector(768)\n",
    "                )\n",
    "            \"\"\")\n",
    "create_table() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76cf6038-819d-45c3-8b47-16888eedeea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 데이터 (원문 + 임베딩결과) 입력\n",
    "def insert_embeddings():\n",
    "\n",
    "    with get_connection() as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            for index, row in embedding_df.iterrows():\n",
    "                cur.execute(\"INSERT INTO vntg_embeddings (content, embedding) VALUES (%s, %s)\", (row['content'],row['embedding']))\n",
    "\n",
    "insert_embeddings()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c84a56e-1cb3-4202-9a07-dc5dbb09459a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 질문과 관련된 문서 추출 함수\n",
    "def get_embedding_matches(vector, num_matches = 4):\n",
    "    similarity_threshold = 0.1\n",
    "    #num_matches = 3\n",
    "    matches = []\n",
    "    with get_connection() as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"\"\"\n",
    "            WITH vector_matches AS (\n",
    "              SELECT uuid, 1 - (embedding <=> %s::vector) AS similarity\n",
    "              FROM vntg_embeddings\n",
    "              WHERE 1 - (embedding <=> %s::vector) > %s \n",
    "              ORDER BY similarity DESC\n",
    "              LIMIT %s\n",
    "            )\n",
    "            SELECT t1.uuid, t1.content, t2.similarity FROM vntg_embeddings t1, vector_matches t2 WHERE t1.uuid=t2.uuid\n",
    "            ORDER BY t2.similarity DESC\n",
    "            \"\"\",(vector, vector, similarity_threshold, num_matches))\n",
    "            results = cur.fetchall()\n",
    "            for r in results:\n",
    "                matches.append(\n",
    "                    {\n",
    "                        \"cid\":r[0],\n",
    "                        \"content\":r[1]\n",
    "                    }\n",
    "                )\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d704a21-0d44-42d0-87a6-7a174c876148",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 채용결격사유에는 다음과 같은 사유가 있다. \n",
      "① 피성년후견인 또는 피한정후견인 \n",
      "② 파산자로서 복권되지 않은 자 \n",
      "③ 병역의무자로서 기피 중에 있는 자 \n",
      "④ 신체 또는 정신상의 장애로 직무를 감당할 수 없다고 인정되는 자 \n",
      "⑤ 금고이상의 형을 받고 그 집행이 종료되거나 집행을 받지 아니하기로 확정된 후 2년을 경과하지 않은 자 \n",
      "⑥ 전 근무지에서 불법적 노동행위로 해고된 자 \n",
      "⑦ 채용 시 허위사실이 있는 서류를 제출한 자 \n",
      "⑧ 기타 위에 준하는 채용결격사유에 해당하는 자\n"
     ]
    }
   ],
   "source": [
    "# 결과 호출\n",
    "embeddings_service = VertexAIEmbeddings(model_name=\"textembedding-gecko-multilingual@latest\")\n",
    "\n",
    "question = '채용결격사유에 대한 사례 알려줘'\n",
    "prompt_template = \"\"\"Answer the questions correctly only within the context provided. If the answer is\n",
    "                not contained in the context, say \"answer not available in context\" \\n\\n\n",
    "                Context: \\n {context}?\\n\n",
    "                Question: \\n {question} \\n\n",
    "                Answer:\n",
    "              \"\"\"\n",
    "\n",
    "qe = embeddings_service.embed_query(question)\n",
    "\n",
    "matches = get_embedding_matches(qe)\n",
    "\n",
    "docs = [Document(page_content=t[\"content\"]) for t in matches]\n",
    "\n",
    "llm = VertexAI(temperature=0, model_name=\"text-bison-32k\", max_output_tokens=512)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "stuff_chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=prompt)\n",
    "\n",
    "stuff_answer = stuff_chain(\n",
    "    {\"input_documents\": docs, \"question\": question}, return_only_outputs=True\n",
    ")\n",
    "\n",
    "print(stuff_answer[\"output_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b8a912-21de-47c6-a76b-580e660e6917",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
